{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "A package (or library) contains several functions useful in a particular context. Here we import some packages that are generally used in science projects:\n",
    "\n",
    "- pandas: to manipulate datasets\n",
    "- numpy: to apply mathematical functions\n",
    "- matplotlib: to display graphs\n",
    "- sklearn: contains a lot of machine learning functions and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# import model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "In this part, we use the pandas library in order to import the data into our notebook. The data is then saved into a dataframe called *dataset_bike*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data into a dataframe\n",
    "dataset_bike = pd.read_csv(\"###CODE HERE###\",\n",
    "                           sep = ',',\n",
    "                           header=0,\n",
    "                           skip_blank_lines=True,\n",
    "                           index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the shape of this dataframe: (nb of rows, nb of columns)\n",
    "print(\"The shape of the dataframe is :\", \"###CODE HERE###\".shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show the first rows of the dataframe\n",
    "dataset_bike.\"###CODE HERE###\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to be able to accuratly predict the number of bike that are rented at a given hour. It is the variable **cnt**. To do that, we have access to 2 years of records, including several features such as:\n",
    "- meteorological measures (temp, atemp, hum, weathersit, windspeed)\n",
    "- datetime information (hr, holiday, weekday, yr, mth..)\n",
    "\n",
    "**GOAL raised by your client**: Your model must be able to predict the hourly demand on random samples with a MAE **smaller than 30 bikes**...\n",
    "\n",
    "MAE: Mean Absolute Error\n",
    "\n",
    "$$MAE=\\frac{1}{n}\\sum_{i=0}^n|pred_i- target_i|$$\n",
    "\n",
    "With:\n",
    "- $n$: number of samples\n",
    "- $pred_i$: predicted demand for sample i\n",
    "- $target_i$: real demand for sample i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get a basic statistical description of your data\n",
    "dataset_bike.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot distributions for temp, atemp, hum and windspeed\n",
    "for variable in [\"temp\", \"atemp\", \"hum\", \"windspeed\"]:\n",
    "    dataset_bike[variable].plot.density(legend=True, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that *humidity* is often equal to 0. Let's assume that these measures are actually missing measures. We will try later to replace them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "In this part, we will prepare our dataframe so it can be ingested by a machine learning model. The main idea is:\n",
    "- to get rid or replace missing values: this is called **missing values imputation**\n",
    "- to keep only numerical variables. Categorical variables have to be encoded: this called **dummification**\n",
    "- if possible try to create new variables from the ones that already exist. These new variables can improve predictions if they bring *signal*: this is called **feature engineering**\n",
    "- to split our dataframe in 2 parts. A first one will be used for **training** our model, the other one will be for **testing the performance** of this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation of missing values\n",
    "Here we will assume that if the *windspeed* = 0 this means that the measure is actually missing.\n",
    "What do we do with these missing values? Several options are possible, you can either:\n",
    "- delete samples that contains missing values\n",
    "- replace missing values by the average or median value of the series\n",
    "- more sophisticated operations (like training another model in order to predict the missing humity)\n",
    "\n",
    "I suggest to simply replace zeros by the average *windspeed* measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bike_missing_values = dataset_bike.copy()\n",
    "\n",
    "# Compute average windspeed\n",
    "mean_windspeed = dataset_bike[\"###CODE HERE###\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign this value to windspeed when windspeed == 0\n",
    "dataset_bike_missing_values.loc[dataset_bike_missing_values[\"windspeed\"] == \"###CODE HERE###\", \"windspeed\"] = mean_windspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot again the distribution to check that there is no windspeed set to 0\n",
    "dataset_bike_missing_values[\"windspeed\"].plot.density(legend=True, figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering\n",
    "In this part, we will add new columns to our dataset, and hope that it will bring signal to our model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bike_feature_engineering = dataset_bike_missing_values.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New variable 1: nb of days since 1st record\n",
    "Let's add a new column to our dataframe that contain the number of days since the day 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to say to Pandas that the dteday column is a date\n",
    "dataset_bike_feature_engineering[\"dteday\"] = pd.to_datetime(dataset_bike_feature_engineering[\"dteday\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of day 1\n",
    "min_date = min(dataset_bike_feature_engineering[\"dteday\"])\n",
    "\n",
    "# create the new column\n",
    "dataset_bike_feature_engineering[\"nb_days_since_1st_day\"] = (dataset_bike_feature_engineering[\"dteday\"] - \"###CODE HERE###\").dt.days.astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the last rows of your dataframe\n",
    "dataset_bike_feature_engineering.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New variable 2: split the day in time slots\n",
    "Now let's split the day in morning, noon, afternoon, evening and night. You will create a new column (feature) that gives you this information (based on *hr*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to describe the mapping between the hour and the part of the day\n",
    "time_slot_mapping = {\n",
    "    0: \"night\",\n",
    "    1: \"night\",\n",
    "    2: \"night\",\n",
    "    3: \"###CODE HERE###\",\n",
    "    4: \"night\",\n",
    "    5: \"night\",\n",
    "    6: \"night\",\n",
    "    7: \"morning\",\n",
    "    8: \"morning\",\n",
    "    9: \"morning\",\n",
    "    10: \"morning\",\n",
    "    11: \"morning\",\n",
    "    12: \"noon\",\n",
    "    13: \"noon\",\n",
    "    14: \"afternoon\",\n",
    "    15: \"afternoon\",\n",
    "    16: \"afternoon\",\n",
    "    17: \"afternoon\",\n",
    "    18: \"afternoon\",\n",
    "    19: \"evening\",\n",
    "    20: \"evening\",\n",
    "    21: \"evening\",\n",
    "    22: \"night\",\n",
    "    23: \"night\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the new variable, and apply the mapping on the hour\n",
    "dataset_bike_feature_engineering[\"time_slot\"] = dataset_bike_feature_engineering[\"hr\"].map(time_slot_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_bike_feature_engineering.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New variable 3: meteo attractiveness\n",
    "I imagine that it is more motivating to use a bike on a sunny and warm day than on the rainy and cold day. As a consequence, let's create a new feature that would give the information \"perfect_conditions\", \"worst_conditions\" or \"average_conditions\" depending on the meteorological features (*temp, hum, weathersit, windspeed*). This is totally subjective, but maybe this will improve your model. Let's see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function that returns the motivation depending on meteo conditions\n",
    "def get_meteo_attractiveness(weather_situation, temperature, humidity, windspeed):\n",
    "    if (weather_situation in [1,2]) and (temperature > 0.3) and (humidity < 0.7) and (windspeed < 0.6):\n",
    "        return \"perfect_conditions\"\n",
    "    elif (weather_situation in [3,4]) and ((temperature < 0.3) or (humidity > 0.7) or (windspeed > 0.7)):\n",
    "        return \"worst_conditions\"\n",
    "    else:\n",
    "        return \"average_conditions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new column and apply the function\n",
    "dataset_bike_feature_engineering[\"meteo_conditions\"] = \\\n",
    "    dataset_bike_feature_engineering.\\\n",
    "            apply(lambda row: get_meteo_attractiveness(row[\"weathersit\"],\n",
    "                                                       row['temp'],\n",
    "                                                       row['hum'],\n",
    "                                                       row['windspeed']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bike_feature_engineering.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummification\n",
    "\n",
    "The dummification is a function that transpose a column to a set of columns in a dataframe, such as:\n",
    "\n",
    "| Column |\n",
    "|------|\n",
    "|   a  |\n",
    "|   b  |\n",
    "|   b  |\n",
    "|   c  |\n",
    "|   a  |\n",
    "\n",
    "becomes \n",
    "\n",
    "| is_a | is_b | is_c |\n",
    "|------|------|------|\n",
    "|   1  |   0  |   0  |\n",
    "|   0  |   1  |   0  |\n",
    "|   0  |   1  |   0  |\n",
    "|   0  |   0  |   1  |\n",
    "|   1  |   0  |   0  |\n",
    "\n",
    "All the textual variables have to be dummified in order to keep only numerical values in our dataset. We can also apply dummification to numerical variables if there is not a relational ranking among the values. Here we will apply this function to *weathersit* and *season*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bike_dummified = dataset_bike_feature_engineering.copy()\n",
    "\n",
    "# define a list that contain all the columns to dummify\n",
    "columns_to_dummify = [\"time_slot\", \"meteo_conditions\", \"weathersit\", \"season\"]\n",
    "\n",
    "# Now let's apply dummification\n",
    "for col in columns_to_dummify:\n",
    "    dataset_bike_dummified = pd.concat([dataset_bike_dummified, pd.get_dummies(dataset_bike_feature_engineering[col], prefix=col)], axis=1)\n",
    "    dataset_bike_dummified = dataset_bike_dummified.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_bike_dummified.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test\n",
    "Now, you have to choose which features will be taken as input in your model, and which one is the **target**.\n",
    "Then, let's split your dataframe into train and test. Usually, we use the letter **X** to talk about the features, and **y** for the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove_in_training = [\"instant\", \"dteday\", \"atemp\", \"cnt\"]\n",
    "\n",
    "# let's define a variable that contains the list of features to keep for the model\n",
    "features_training = [col for col in dataset_bike_dummified.columns if col not in columns_to_remove_in_training]\n",
    "\n",
    "target_feature = \"###CODE HERE###\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split your dataframe randomly in order to keep 80% of the samples for training, 20% for testing (also called evaluation).\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset_bike_dummified[features_training],\n",
    "                                                    dataset_bike_dummified[target_feature],\n",
    "                                                    test_size=0.2, random_state= 1234)\n",
    "\n",
    "# print the shapes\n",
    "print(\"Shape X_train :\", \"###CODE HERE###\".shape)\n",
    "print(\"Shape X_test :\", X_test.shape)\n",
    "print(\"Shape y_train :\", \"###CODE HERE###\".shape)\n",
    "print(\"Shape y_test :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Now, your dataframe is ready! You have to choose a model and train it on your data.\n",
    "Let's take only one type of model for the moment, a simple one: the linear regression.\n",
    "\n",
    "Training your model is pretty simple thanks to the scikit-learn package! Let's see how it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Mutivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an \"empty\" model\n",
    "lreg = LinearRegression(fit_intercept = False)\n",
    "\n",
    "# fit (=train) this model. => this is when the model is looking for the best surface in \n",
    "# a vectorial space that minimise the distance between samples.\n",
    "lreg.fit(\"###CODE HERE###\" ,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The model is trained. Now it is time to run an evaluation to see if your model meets the expectations of your client (MAE < 30 bikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions on Train\n",
    "lreg_pred_train = lreg.predict(X_train)\n",
    "# Compute predictions on Test: this will be used for evaluation\n",
    "lreg_pred_test = lreg.predict(\"###CODE HERE###\")\n",
    "\n",
    "# Evaluate\n",
    "print(\"MAE Training = \", mean_absolute_error(lreg_pred_train, \"###CODE HERE###\"))\n",
    "print(\"***** MAE Test = \", mean_absolute_error(lreg_pred_test, y_test), \" ******\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great new, you improved your previous model! **Unfortunatly, it seems that \"MAE Test\" is still not small enough to satisfy your client :/.** In the next Notebooks, we will try to use other models in order to improve your score!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
